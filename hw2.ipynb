{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The modules we're going to use\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, pooling, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import callbacks\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "\n",
    "# When you execute a code to plot with a simple SHIFT-ENTER, the plot will be shown directly under the code cell\n",
    "%matplotlib inline\n",
    "\n",
    "# Set backend data format\n",
    "from keras import backend as K\n",
    "print('Default format:', K.image_data_format())\n",
    "K.set_image_data_format('channels_first')\n",
    "print('Current format:', K.image_data_format())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to load/save data\n",
    "def load_data(file_name):\n",
    "    data = []\n",
    "    with open(file_name) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            data.append([int(x) for x in row])\n",
    "    return data\n",
    "    \n",
    "def load_feature(file_name):\n",
    "    return np.array(load_data(file_name), 'float32')\n",
    "\n",
    "def load_target(file_name):\n",
    "    targets = load_data(file_name)\n",
    "    # class should start from 0\n",
    "    num_classes = np.max(targets) + 1\n",
    "    return np_utils.to_categorical(targets, num_classes)\n",
    "\n",
    "def save_result(result, file_name='test_target.csv'):\n",
    "    with open(file_name, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['Id', 'Category']) # Header\n",
    "        for i in range(len(result)): # Targets\n",
    "            writer.writerow([i, result[i]])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_X = 'data/train_data.csv'\n",
    "file_y = 'data/train_target.csv'\n",
    "X = load_feature(file_X)\n",
    "y = load_target(file_y)\n",
    "\n",
    "# Data scaling\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Pre-processing\n",
    "print('Before pre-processing, X_train size: ', X.shape)\n",
    "X = X.reshape(-1, 1, 48, 48)\n",
    "print('After pre-processing, X_train size: ', X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model design\n",
    "def createModel():\n",
    "    # Define dropout rate\n",
    "    dprate = 0.5;\n",
    "\n",
    "    # Create a neural net\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional layers\n",
    "    model.add(Conv2D(64, (3,3), strides=1, padding='same', activation='relu', input_shape=(1,48,48), name='c64_1'))\n",
    "    model.add(Conv2D(64, (3,3), strides=1, padding='same', activation='relu', name='c64_2'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid', name='mp64'))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), strides=1, padding='same', activation='relu', name='c128_1'))\n",
    "    model.add(Conv2D(128, (3,3), strides=1, padding='same', activation='relu', name='c128_2'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid', name='mp128'))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), strides=1, padding='same', activation='relu', name='c256_1'))\n",
    "    model.add(Conv2D(256, (3,3), strides=1, padding='same', activation='relu', name='c256_2'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='valid', name='mp256'))\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(1024, activation='relu', name='d1024_1'))\n",
    "    model.add(Dropout(dprate, name='dp_1'))\n",
    "    model.add(Dense(1024, activation='relu', name='d1024_2'))\n",
    "    model.add(Dropout(dprate, name='dp_2'))\n",
    "    model.add(Dense(3, activation='softmax', name='d3'))\n",
    "    \n",
    "    # Specify an optimizer to use\n",
    "    adam = Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    # Choose loss function, optimization method, and metrics (which results to display)\n",
    "    model.compile(\n",
    "        optimizer = adam,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model = createModel()\n",
    "# early_stop = callbacks.EarlyStopping(monitor='val_acc', patience=2, verbose=2)\n",
    "# history = model.fit(X,y,epochs=100,batch_size=32,validation_split=0.1, callbacks=[early_stop], verbose=2)\n",
    "history = model.fit(X,y,epochs=8,batch_size=32,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load predicting data\n",
    "file_X_predict = 'data/test_data.csv'\n",
    "X_predict = load_feature(file_X_predict)\n",
    "\n",
    "# Data scaling\n",
    "X_predict = scaler.transform(X_predict)\n",
    "\n",
    "# Pre-processing\n",
    "X_predict = X_predict.reshape(-1,1, 48,48)\n",
    "print('X predict size: ', X_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting\n",
    "y_predict = model.predict(X_predict)\n",
    "\n",
    "# convert probs to class\n",
    "y_result = [np.argmax(probs) for probs in y_predict]\n",
    "\n",
    "# Save predicting result to file\n",
    "save_result(y_result, 'data/test_target.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image of one predicting example\n",
    "index = np.random.randint(X_predict.shape[0],size=1)\n",
    "plt.imshow(X_predict[index[0],0,:,:],cmap='gray')\n",
    "\n",
    "# Get its prediction\n",
    "output = y_predict[index[0]]\n",
    "print(\"Probs: \", output)\n",
    "print(\"Class: \", y_result[index[0]])\n",
    "plt.figure()\n",
    "plt.xticks(np.arange(output.shape[0]))\n",
    "plt.plot(np.arange(output.shape[0]),output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist model\n",
    "model.save('data/model_642_1282_2562-10242.h5')\n",
    "model.save_weight2('data/weights_642_1282_2562-10242.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
